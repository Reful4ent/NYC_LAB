{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Вариант 3. Квантование весов для NPU\n",
        "\n",
        "Реализация квантования весов нейронной сети из float32 в int8 для использования в NPU:\n",
        "- функция квантования весов;\n",
        "- класс `QuantizedLayer` с хранением квантованных весов и forward с деквантованием;\n",
        "- сравнение точности до и после квантования на простых данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Импорты\n",
        "from __future__ import annotations\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Функция квантования весов float32 → int8\n",
        "\n",
        "Симметричное квантование: масштаб по максимуму абсолютных значений, веса приводятся к диапазону int8 [-128, 127]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def quantize_weights(weights_float: np.ndarray) -> tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Квантует веса из float32 в int8 для использования в NPU (симметричное квантование).\n",
        "\n",
        "    Масштаб: scale = max(|weights|) / 127. Значения округляются и ограничиваются [-128, 127].\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    weights_float : np.ndarray\n",
        "        Массив весов в float32, форма (out_features, in_features) или любая 2D.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tuple[np.ndarray, float]\n",
        "        (weights_int8, scale): квантованные веса в int8 и масштаб для деквантования.\n",
        "    \"\"\"\n",
        "    w = np.asarray(weights_float, dtype=np.float64)\n",
        "    w_max = np.max(np.abs(w))\n",
        "    if w_max == 0:\n",
        "        scale = 1.0\n",
        "        weights_int8 = np.zeros(w.shape, dtype=np.int8)\n",
        "        return weights_int8, scale\n",
        "    scale = w_max / 127.0\n",
        "    weights_int8 = np.round(w / scale).astype(np.float64).clip(-128, 127).astype(np.int8)\n",
        "    return weights_int8, float(scale)\n",
        "\n",
        "\n",
        "def dequantize_weights(weights_int8: np.ndarray, scale: float) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Восстанавливает веса из int8 в float для вычислений (деквантование).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    weights_int8 : np.ndarray\n",
        "        Квантованные веса, dtype int8.\n",
        "    scale : float\n",
        "        Масштаб, использованный при квантовании.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Веса в float64 (приближение исходных float32).\n",
        "    \"\"\"\n",
        "    return weights_int8.astype(np.float64) * scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Класс QuantizedLayer\n",
        "\n",
        "Хранит квантованные веса (int8) и масштаб; при forward выполняет деквантование и линейное преобразование."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class QuantizedLayer:\n",
        "    \"\"\"\n",
        "    Линейный слой с квантованными весами (int8) для NPU.\n",
        "    Хранит веса в int8 и при forward деквантует их на лету и выполняет Y = X @ W^T.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weights_float: np.ndarray):\n",
        "        \"\"\"\n",
        "        Инициализация: квантует переданные веса float32 и сохраняет int8 + scale.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_float : np.ndarray\n",
        "            Матрица весов (out_features, in_features) в float32.\n",
        "        \"\"\"\n",
        "        self._weights_int8, self._scale = quantize_weights(weights_float)\n",
        "        self._out_features, self._in_features = self._weights_int8.shape\n",
        "\n",
        "    @property\n",
        "    def weights_int8(self) -> np.ndarray:\n",
        "        \"\"\"Квантованные веса (int8).\"\"\"\n",
        "        return self._weights_int8\n",
        "\n",
        "    @property\n",
        "    def scale(self) -> float:\n",
        "        \"\"\"Масштаб для деквантования.\"\"\"\n",
        "        return self._scale\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Прямое распространение: деквантование весов и умножение x @ W^T.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : np.ndarray\n",
        "            Входной батч, форма (batch_size, in_features).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Выход формы (batch_size, out_features).\n",
        "        \"\"\"\n",
        "        w = dequantize_weights(self._weights_int8, self._scale)\n",
        "        return x @ w.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Сравнение точности до и после квантования\n",
        "\n",
        "Используем простую регрессию: данные из `make_regression`, линейная модель на float32 (через явные веса), затем те же веса квантуем в `QuantizedLayer` и сравниваем MSE и MAE на тесте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Генерация простых данных и обучение \"модели\" (линейная регрессия через нормальное уравнение)\n",
        "np.random.seed(42)\n",
        "n_samples, n_features = 500, 20\n",
        "X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=5.0, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "# Добавляем столбец единиц для bias\n",
        "X_train_b = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
        "X_test_b = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
        "\n",
        "# Веса методом нормальных уравнений: W = (X'X)^(-1) X' y  -> (n_features+1,) для одной цели\n",
        "# Для единообразия с QuantizedLayer храним веса как (1, in_features)\n",
        "w_opt = np.linalg.lstsq(X_train_b, y_train.reshape(-1, 1), rcond=None)[0]\n",
        "weights_float = w_opt.T  # (1, n_features+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Предсказания до квантования (float32)\n",
        "y_pred_float = (X_test_b @ weights_float.T).flatten()\n",
        "mse_float = mean_squared_error(y_test, y_pred_float)\n",
        "mae_float = mean_absolute_error(y_test, y_pred_float)\n",
        "print(\"До квантования (float32):\")\n",
        "print(f\"  MSE = {mse_float:.4f}, MAE = {mae_float:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Квантованный слой и предсказания после квантования\n",
        "qlayer = QuantizedLayer(weights_float)\n",
        "y_pred_quant = qlayer.forward(X_test_b).flatten()\n",
        "mse_quant = mean_squared_error(y_test, y_pred_quant)\n",
        "mae_quant = mean_absolute_error(y_test, y_pred_quant)\n",
        "print(\"После квантования (int8 + деквантование в forward):\")\n",
        "print(f\"  MSE = {mse_quant:.4f}, MAE = {mae_quant:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Сводка сравнения\n",
        "print(\"\\n--- Сравнение точности ---\")\n",
        "print(f\"  MSE:  float32 = {mse_float:.4f}, int8 = {mse_quant:.4f}, относительное изменение = {(mse_quant - mse_float) / (mse_float + 1e-10) * 100:+.2f}%\")\n",
        "print(f\"  MAE:  float32 = {mae_float:.4f}, int8 = {mae_quant:.4f}, относительное изменение = {(mae_quant - mae_float) / (mae_float + 1e-10) * 100:+.2f}%\")\n",
        "print(\"\\nКвантование в int8 даёт небольшое ухудшение метрик из-за округления; для NPU это компромисс между точностью и скоростью/энергоэффективностью.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Дополнительно: проверка деквантованных весов (ошибка квантования)\n",
        "w_restored = dequantize_weights(qlayer.weights_int8, qlayer.scale)\n",
        "weight_error = np.abs(weights_float.astype(np.float64) - w_restored)\n",
        "print(\"Ошибка восстановления весов после квантования:\")\n",
        "print(f\"  max |w_float - w_dequant| = {np.max(weight_error):.6f}\")\n",
        "print(f\"  mean |w_float - w_dequant| = {np.mean(weight_error):.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}